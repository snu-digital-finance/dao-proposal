{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('../proposals_preprocess_0812.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title & Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __remove_pattern(text):\n",
    "    return text.translate(\n",
    "        str.maketrans('', '', '>#\\'\\\"\\*:-.0123456789')).strip()\n",
    "\n",
    "def __is_in(text, arr):\n",
    "    return any([word in text for word in arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_duplicates_preserve_order(arr):\n",
    "    return list(dict.fromkeys(arr))\n",
    "\n",
    "def _is_valid(text, category):\n",
    "    text = __remove_pattern(text)\n",
    "    if not category.limit.is_valid_length(len(text)):\n",
    "        return False\n",
    "\n",
    "    text = text.lower()\n",
    "    return (not __is_in(text, category.not_words)) and __is_in(text, category.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.extract.data import categories\n",
    "from util.extract.extract import extract_title_and_content\n",
    "\n",
    "def _generate_title(text):\n",
    "    for v in [\"TLDR \", \"TL;DR \", \"TL,DR \", \"TLDR: \", \"TLDR; \", \"The TL;DR of the document:\"]:\n",
    "        text = text.replace(v, f\"# TLDR\\n\")\n",
    "\n",
    "    texts = []\n",
    "    for t in text.split(\"\\n\"):\n",
    "        t = t.strip()\n",
    "        if not t: continue;\n",
    "        temp = t.lower()\n",
    "        if categories[\"title\"].limit.is_valid_length(len(temp)) \\\n",
    "            and \"#\" not in temp \\\n",
    "            and (\n",
    "                __is_in(temp, categories[\"title\"].words) \n",
    "                or __is_in(temp, categories[\"title\"].other_words) \n",
    "        ):  \n",
    "            t = f\"# {t}\"\n",
    "        texts.append(t)\n",
    "    return \"\\n\".join(texts)\n",
    "\n",
    "def _get_title_and_content(text):\n",
    "    titles, contents = extract_title_and_content(text)\n",
    "    result = [\n",
    "        f\"<Title>: {title}\\n{content}\\n\"\n",
    "        for title, content in zip(titles, contents)\n",
    "        if _is_valid(title, categories[\"title\"])\n",
    "    ]\n",
    "    return \"\\n\".join(\n",
    "            _remove_duplicates_preserve_order(result)\n",
    "        ) if result else None\n",
    "\n",
    "MIN_LIMIT = 5\n",
    "def _get_sentence(text):\n",
    "    content = []\n",
    "    texts = text.split(\"\\n\")\n",
    "    idx = -1\n",
    "    while idx < len(texts) - 1:\n",
    "        idx += 1\n",
    "        temp = __remove_pattern(texts[idx])\n",
    "        if _is_valid(temp, categories[\"sentence\"]) :\n",
    "            content.append(f\"<Sentence>: {texts[idx].strip()}\")\n",
    "            if idx < len(texts) - 2 and texts[idx].strip()[-1] == \":\":\n",
    "                idx += 1\n",
    "                now = texts[idx].strip()\n",
    "                if len(__remove_pattern(now)) < MIN_LIMIT: continue;\n",
    "\n",
    "                nex = texts[idx+1].strip()\n",
    "                content.append(f\"{now}\")\n",
    "                while idx < len(texts) - 2 \\\n",
    "                    and len(__remove_pattern(nex)) >= MIN_LIMIT \\\n",
    "                    and now[0] == nex[0]:\n",
    "                    idx += 1\n",
    "                    content.append(f\"{nex}\")\n",
    "                    now = nex\n",
    "                    nex = texts[idx+1].strip()\n",
    "                    \n",
    "            content.append(\"\\n\")\n",
    "                    \n",
    "    return \"\\n\".join(content) if content else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20918, 38) 9256\n"
     ]
    }
   ],
   "source": [
    "from util.extract.data import not_sentence\n",
    "\n",
    "def filter_words(text):\n",
    "    for v in not_sentence:\n",
    "        text = text.replace(v, \"\")\n",
    "    sentence_result = _get_sentence(text)\n",
    "\n",
    "    result = _get_title_and_content(text)\n",
    "    if not result: \n",
    "        text = _generate_title(text)\n",
    "        result = _get_title_and_content(text)\n",
    "    \n",
    "    if result and sentence_result:\n",
    "        return f\"{result}\\n{sentence_result}\"\n",
    "    elif result:\n",
    "        return result\n",
    "    elif sentence_result:\n",
    "        return sentence_result\n",
    "    return None\n",
    "\n",
    "df[\"filtered_body\"] = df[\"body\"].apply(filter_words)\n",
    "df.sort_values(\n",
    "    by=\"filtered_body\"\n",
    ").to_excel('proposals_preprocess_filtered.xlsx', index=False)\n",
    "\n",
    "print(df.shape, df[\"filtered_body\"].isna().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
