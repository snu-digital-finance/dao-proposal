{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20750, 39)\n",
      "(253, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"proposals_preprocess_0812_cleaned.xlsx\")\n",
    "print(df.shape)\n",
    "empty_body = pd.read_excel(\"empty_body.xlsx\")\n",
    "print(empty_body.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 39)\n",
      "(45, 39)\n"
     ]
    }
   ],
   "source": [
    "# Title has [Election, Candidate] \n",
    "\n",
    "temp = df[\"title\"].str.contains(\"Multi-sig Governance\")\n",
    "candidate = df[temp]\n",
    "print(candidate.shape)\n",
    "print(candidate[candidate[\"body\"].str.contains(\"multi-sig owners\")].shape)\n",
    "\n",
    "df.loc[temp, \"Class A\"] = \"Operations\"\n",
    "df.loc[temp, \"Class B\"] = \"Team\"\n",
    "df.loc[temp, \"Class C\"] = \"Hiring\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"title\"].str.contains(\"Multi-sig Governance\") # 45 rows\n",
    "temp2 = df[\"body_lower\"].isnull()\n",
    "df_ = df[~(temp1 | temp2)].sort_values(by=[\"body_lower\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\32mou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\32mou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\32mou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\32mou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\32mou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\32mou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in [\"title\", \"body\"]:\n",
    "    df_[f\"{v}_filtered\"] = df_[f\"{v}_lower\"].astype(str) \\\n",
    "        .str.replace(\"[^a-z\\n]\", \" \", regex=True).str.strip() \\\n",
    "            .apply(lambda x: ' '.join(\n",
    "            (w for w in word_tokenize(x) if not w in stop_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from pattern.en import lemma, singularize\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def is_word_in_dictionary(word):\n",
    "    for w in set([word, singularize(word), lemma(word)]):\n",
    "        if len(wordnet.synsets(w)) > 0:\n",
    "            return True\n",
    "    return False\n",
    "print(is_word_in_dictionary(\"apples\"))  # True (복수형 단어가 기본형으로 변환됨)\n",
    "print(is_word_in_dictionary(\"ate\"))     # True (과거형으로 변환된 단어가 기본형으로 변환됨)\n",
    "print(is_word_in_dictionary(\"qwerty\"))  # False (사전에 없는 단어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57668\n",
      "14567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'timelockdelay',\n",
       " 'bulkremovevalidator',\n",
       " 'rhinostake',\n",
       " 'metaversedao',\n",
       " 'hailey',\n",
       " 'defieye',\n",
       " 'heavely',\n",
       " 'communtities',\n",
       " 'magenes',\n",
       " 'mojito',\n",
       " 'medelln',\n",
       " 'minterface',\n",
       " 'casstoshi',\n",
       " 'blocktools',\n",
       " 'excessfeerefundaddress',\n",
       " 'pgps',\n",
       " 'memeish',\n",
       " 'readdressed',\n",
       " 'avantgardefi',\n",
       " 'hhuh',\n",
       " 'bntdapp',\n",
       " 'savvio',\n",
       " 'ottonamas',\n",
       " 'hynix',\n",
       " 'cdm',\n",
       " 'optitrack',\n",
       " 'apebot',\n",
       " 'episdio',\n",
       " 'semanas',\n",
       " 'hhmi',\n",
       " 'grosso',\n",
       " 'cryptosavingexpert',\n",
       " 'apolmaticx',\n",
       " 'valueif',\n",
       " 'cringy',\n",
       " 'decentralandgame',\n",
       " 'vanwitzenburg',\n",
       " 'eran',\n",
       " 'superpat',\n",
       " 'impactfully',\n",
       " 'upyfi',\n",
       " 'relase',\n",
       " 'collectivly',\n",
       " 'spencecoin',\n",
       " 'sokravtsov',\n",
       " 'proxyoft',\n",
       " 'blockhive',\n",
       " 'phantabear',\n",
       " 'cyclesnew',\n",
       " 'intokens',\n",
       " 'microclimate',\n",
       " 'eso',\n",
       " 'votants',\n",
       " 'gtbrs',\n",
       " 'musuka',\n",
       " 'kqhozolk',\n",
       " 'poiln',\n",
       " 'klaapwqhf',\n",
       " 'westbrook',\n",
       " 'tigo',\n",
       " 'temporature',\n",
       " 'kalamata',\n",
       " 'rostros',\n",
       " 'discussionstypically',\n",
       " 'dapposs',\n",
       " 'cabinvc',\n",
       " 'experienceproposal',\n",
       " 'pitzalis',\n",
       " 'balogh',\n",
       " 'wpy',\n",
       " 'gotchiguess',\n",
       " 'valut',\n",
       " 'shutterised',\n",
       " 'achiving',\n",
       " 'radpily',\n",
       " 'abitrage',\n",
       " 'ccipadapter',\n",
       " 'uncapping',\n",
       " 'renovadores',\n",
       " 'sesaon',\n",
       " 'aishwary',\n",
       " 'capf',\n",
       " 'aammweth',\n",
       " 'shoul',\n",
       " 'hmagicmagic',\n",
       " 'benfit',\n",
       " 'allowssetcontroller',\n",
       " 'eventdao',\n",
       " 'airdops',\n",
       " 'umaaddress',\n",
       " 'forgining',\n",
       " 'atro',\n",
       " 'ftf',\n",
       " 'especialy',\n",
       " 'primavera',\n",
       " 'boldstart',\n",
       " 'cryptobaba',\n",
       " 'vxm',\n",
       " 'auroboros',\n",
       " 'paratmeters',\n",
       " 'scotty',\n",
       " 'jbdoa',\n",
       " 'platfrom',\n",
       " 'cobie',\n",
       " 'visibilty',\n",
       " 'autompounding',\n",
       " 'unbond',\n",
       " 'leupold',\n",
       " 'kqvtgc',\n",
       " 'patra',\n",
       " 'regualar',\n",
       " 'cachinero',\n",
       " 'redirectional',\n",
       " 'drakula',\n",
       " 'patho',\n",
       " 'comdex',\n",
       " 'standaradization',\n",
       " 'coinledger',\n",
       " 'hartej',\n",
       " 'resistencia',\n",
       " 'subj',\n",
       " 'coq',\n",
       " 'mera',\n",
       " 'fwiw',\n",
       " 'cinesync',\n",
       " 'nik',\n",
       " 'controloer',\n",
       " 'cchain',\n",
       " 'composablestableswap',\n",
       " 'racetracking',\n",
       " 'golfclubs',\n",
       " 'museumdistrict',\n",
       " 'acierto',\n",
       " 'lbfpairmanager',\n",
       " 'genericlender',\n",
       " 'increaed',\n",
       " 'serendale',\n",
       " 'pior',\n",
       " 'unlockamount',\n",
       " 'autobattler',\n",
       " 'anders',\n",
       " 'silopedia',\n",
       " 'lildoge',\n",
       " 'purdy',\n",
       " 'sfxdx',\n",
       " 'sneha',\n",
       " 'fxeur',\n",
       " 'eao',\n",
       " 'chronogram',\n",
       " 'conceptualist',\n",
       " 'vladonsd',\n",
       " 'disolved',\n",
       " 'penguino',\n",
       " 'cleancarbon',\n",
       " 'wagbagc',\n",
       " 'eberg',\n",
       " 'cname',\n",
       " 'nisenson',\n",
       " 'addarbitrumgauge',\n",
       " 'tasliel',\n",
       " 'unbuilt',\n",
       " 'chong',\n",
       " 'igo',\n",
       " 'stusdt',\n",
       " 'cryptoguards',\n",
       " 'dorshkind',\n",
       " 'situbondo',\n",
       " 'xtier',\n",
       " 'metty',\n",
       " 'libfertilizer',\n",
       " 'wearablewednesday',\n",
       " 'jdapbe',\n",
       " 'mphapp',\n",
       " 'ccatkggqweqbtmw',\n",
       " 'griefers',\n",
       " 'ual',\n",
       " 'managedpools',\n",
       " 'idlerai',\n",
       " 'ahhh',\n",
       " 'lastminute',\n",
       " 'exponentiatedreward',\n",
       " 'sant',\n",
       " 'slimh',\n",
       " 'eurn',\n",
       " 'saln',\n",
       " 'bananpus',\n",
       " 'baonties',\n",
       " 'rysk',\n",
       " 'quizhouse',\n",
       " 'hqgenpf',\n",
       " 'bga',\n",
       " 'roatn',\n",
       " 'tokendeployer',\n",
       " 'oncentrated',\n",
       " 'cummunity',\n",
       " 'blasttv',\n",
       " 'pxcao',\n",
       " 'dispatchmessage',\n",
       " 'holley',\n",
       " 'whireguard',\n",
       " 'railjams',\n",
       " 'duips',\n",
       " 'similart',\n",
       " 'networkwe',\n",
       " 'llamaogrants',\n",
       " 'stakeease',\n",
       " 'metabuild',\n",
       " 'igt',\n",
       " 'stetheth',\n",
       " 'sridhar',\n",
       " 'montague',\n",
       " 'stepanova',\n",
       " 'lenster',\n",
       " 'junejuly',\n",
       " 'soundbites',\n",
       " 'aaveeth',\n",
       " 'distributon',\n",
       " 'tghis',\n",
       " 'flashclaim',\n",
       " 'imaginarius',\n",
       " 'consertive',\n",
       " 'accroding',\n",
       " 'firendly',\n",
       " 'tryin',\n",
       " 'mgcs',\n",
       " 'screenprint',\n",
       " 'sugest',\n",
       " 'unisocks',\n",
       " 'overperforms',\n",
       " 'holyn',\n",
       " 'ompatibility',\n",
       " 'mattsons',\n",
       " 'garett',\n",
       " 'nowdays',\n",
       " 'borrowingcap',\n",
       " 'mulitchain',\n",
       " 'questline',\n",
       " 'strickler',\n",
       " 'defunds',\n",
       " 'curvetobdv',\n",
       " 'rearchitecting',\n",
       " 'heremes',\n",
       " 'nkxholderz',\n",
       " 'entrpeneurial',\n",
       " 'factsheet',\n",
       " 'authr',\n",
       " 'autocompouding',\n",
       " 'sobotka',\n",
       " 'gttingen',\n",
       " 'htps',\n",
       " 'ariunaa',\n",
       " 'enxs',\n",
       " 'yvcrvusd',\n",
       " 'dammstrasse',\n",
       " 'simulatetxaccessor',\n",
       " 'regenesisor',\n",
       " 'nikkilemondrop',\n",
       " 'ubiv',\n",
       " 'cru',\n",
       " 'ghaf',\n",
       " 'sgps',\n",
       " 'snowfrow',\n",
       " 'thegreg',\n",
       " 'superstate',\n",
       " 'grinstein',\n",
       " 'spcial',\n",
       " 'acalanto',\n",
       " 'danylo',\n",
       " 'polski',\n",
       " 'backfall',\n",
       " 'chfusd',\n",
       " 'nogles',\n",
       " 'poolmanagerv',\n",
       " 'vardhanam',\n",
       " 'completado',\n",
       " 'zipcy',\n",
       " 'spnft',\n",
       " 'renewedexpect',\n",
       " 'authrophic',\n",
       " 'invoestors',\n",
       " 'panvala',\n",
       " 'walid',\n",
       " 'samanthaj',\n",
       " 'hedsdao',\n",
       " 'alternativas',\n",
       " 'tirzepatide',\n",
       " 'merck',\n",
       " 'xcmag',\n",
       " 'authencity',\n",
       " 'nirlin',\n",
       " 'apoorv',\n",
       " 'elzi',\n",
       " 'vive',\n",
       " 'anhangaba',\n",
       " 'fjlzbrxsg',\n",
       " 'druido',\n",
       " 'throughthough',\n",
       " 'desigers',\n",
       " 'cabugueira',\n",
       " 'sundin',\n",
       " 'adn',\n",
       " 'arbitraguer',\n",
       " 'stumptown',\n",
       " 'queenb',\n",
       " 'againbut',\n",
       " 'popranks',\n",
       " 'ceale',\n",
       " 'ubject',\n",
       " 'ahimbisibwe',\n",
       " 'correctamente',\n",
       " 'deuss',\n",
       " 'supraoracles',\n",
       " 'steths',\n",
       " 'vamxt',\n",
       " 'pomptu',\n",
       " 'aprroved',\n",
       " 'lejeune',\n",
       " 'coinpaper',\n",
       " 'pepole',\n",
       " 'xzoo',\n",
       " 'lockingvault',\n",
       " 'tatouages',\n",
       " 'hre',\n",
       " 'nontrivial',\n",
       " 'nounsauctionhouse',\n",
       " 'yao',\n",
       " 'narang',\n",
       " 'knoshua',\n",
       " 'pleanty',\n",
       " 'deno',\n",
       " 'carabela',\n",
       " 'mahoro',\n",
       " 'mormal',\n",
       " 'ecfb',\n",
       " 'kleroses',\n",
       " 'hartmann',\n",
       " 'puja',\n",
       " 'beavis',\n",
       " 'conscientes',\n",
       " 'treasurywill',\n",
       " 'ashwath',\n",
       " 'hashgraph',\n",
       " 'telangana',\n",
       " 'maxchains',\n",
       " 'testdays',\n",
       " 'oakgroup',\n",
       " 'tstore',\n",
       " 'caave',\n",
       " 'elkdex',\n",
       " 'yesper',\n",
       " 'dappsoverapps',\n",
       " 'neha',\n",
       " 'problematization',\n",
       " 'squidbillies',\n",
       " 'blocksize',\n",
       " 'hester',\n",
       " 'pizzo',\n",
       " 'jcld',\n",
       " 'marais',\n",
       " 'kuacorn',\n",
       " 'spcujed',\n",
       " 'elliex',\n",
       " 'isamazing',\n",
       " 'loking',\n",
       " 'coingeko',\n",
       " 'pcjhdmtfstlyqq',\n",
       " 'pinoys',\n",
       " 'leastwood',\n",
       " 'jokedaos',\n",
       " 'saitham',\n",
       " 'masterchefsushi',\n",
       " 'henrique',\n",
       " 'helpfull',\n",
       " 'poviliauskas',\n",
       " 'zluxke',\n",
       " 'stpeth',\n",
       " 'noiminated',\n",
       " 'intuitiveness',\n",
       " 'webgains',\n",
       " 'hamon',\n",
       " 'ntwrks',\n",
       " 'evoed',\n",
       " 'kingsway',\n",
       " 'chailly',\n",
       " 'transferdeposits',\n",
       " 'lswra',\n",
       " 'wout',\n",
       " 'marsbit',\n",
       " 'subjecthello',\n",
       " 'worksmore',\n",
       " 'sra',\n",
       " 'civically',\n",
       " 'caarts',\n",
       " 'childvotereward',\n",
       " 'unbeetables',\n",
       " 'sunrize',\n",
       " 'cgpts',\n",
       " 'uaws',\n",
       " 'blockuser',\n",
       " 'cakeswap',\n",
       " 'dclsanctuary',\n",
       " 'datos',\n",
       " 'hernndez',\n",
       " 'togglerescue',\n",
       " 'nadal',\n",
       " 'relavent',\n",
       " 'multistrat',\n",
       " 'glasmo',\n",
       " 'multibridge',\n",
       " 'vauge',\n",
       " 'cakeswapchain',\n",
       " 'aaveusdt',\n",
       " 'wendy',\n",
       " 'mathaius',\n",
       " 'eigenpoint',\n",
       " 'comprueba',\n",
       " 'dxaunw',\n",
       " 'sorare',\n",
       " 'contributer',\n",
       " 'sufferedfor',\n",
       " 'hahaschool',\n",
       " 'luxottica',\n",
       " 'forather',\n",
       " 'unconferences',\n",
       " 'pokerspace',\n",
       " 'buscar',\n",
       " 'httpe',\n",
       " 'convocar',\n",
       " 'actualizacin',\n",
       " 'ulises',\n",
       " 'mehak',\n",
       " 'mcopy',\n",
       " 'poltico',\n",
       " 'blxm',\n",
       " 'conetest',\n",
       " 'tsc',\n",
       " 'lvls',\n",
       " 'billyrae',\n",
       " 'manral',\n",
       " 'reachouts',\n",
       " 'validitity',\n",
       " 'maxihost',\n",
       " 'memmbers',\n",
       " 'propasal',\n",
       " 'timshel',\n",
       " 'xpla',\n",
       " 'qwoted',\n",
       " 'discutions',\n",
       " 'mfvyrjxg',\n",
       " 'paymentsplitter',\n",
       " 'thelastjosh',\n",
       " 'goins',\n",
       " 'competative',\n",
       " 'loadout',\n",
       " 'collateralerc',\n",
       " 'colluders',\n",
       " 'deviationratioboundlower',\n",
       " 'psan',\n",
       " 'admitir',\n",
       " 'hkiac',\n",
       " 'nickqian',\n",
       " 'jetpack',\n",
       " 'shub',\n",
       " 'fabde',\n",
       " 'sharifi',\n",
       " 'voitum',\n",
       " 'sushiv',\n",
       " 'mismedicated',\n",
       " 'scalei',\n",
       " 'activision',\n",
       " 'imi',\n",
       " 'justicedaos',\n",
       " 'blocknumbers',\n",
       " 'molins',\n",
       " 'furm',\n",
       " 'smoldapp',\n",
       " 'dhippy',\n",
       " 'dcon',\n",
       " 'wduhpwk',\n",
       " 'viditar',\n",
       " 'gervin',\n",
       " 'tribeca',\n",
       " 'luebeck',\n",
       " 'exclusivamente',\n",
       " 'domani',\n",
       " 'skelator',\n",
       " 'phoenixduc',\n",
       " 'leverageable',\n",
       " 'velez',\n",
       " 'feifrax',\n",
       " 'qmyk',\n",
       " 'sisyphos',\n",
       " 'mumbo',\n",
       " 'rsvcrv',\n",
       " 'iusdc',\n",
       " 'xvbkmqxvkaue',\n",
       " 'incurr',\n",
       " 'harvestableindex',\n",
       " 'mandyjennifa',\n",
       " 'purchses',\n",
       " 'underthesea',\n",
       " 'razonamiento',\n",
       " 'tweetdeck',\n",
       " 'votelocked',\n",
       " 'darkwillow',\n",
       " 'corliano',\n",
       " 'hurst',\n",
       " 'wdpqeq',\n",
       " 'koroushnia',\n",
       " 'ecp',\n",
       " 'mcfly',\n",
       " 'mentallic',\n",
       " 'ouroboroscapital',\n",
       " 'puripat',\n",
       " 'clara',\n",
       " 'reconciliate',\n",
       " 'easte',\n",
       " 'nacin',\n",
       " 'beyto',\n",
       " 'voytech',\n",
       " 'undelegated',\n",
       " 'hyperdex',\n",
       " 'tradesize',\n",
       " 'etherocks',\n",
       " 'hsms',\n",
       " 'staticcalls',\n",
       " 'senseinodes',\n",
       " 'claimwithdrawal',\n",
       " 'comiccon',\n",
       " 'installer',\n",
       " 'blackbear',\n",
       " 'dreamteam',\n",
       " 'jakubx',\n",
       " 'antive',\n",
       " 'xenschool',\n",
       " 'evalute',\n",
       " 'ultrabase',\n",
       " 'networksethereum',\n",
       " 'flipdao',\n",
       " 'guildstock',\n",
       " 'signatue',\n",
       " 'fuelband',\n",
       " 'qmuskiqbfmdbq',\n",
       " 'reboarding',\n",
       " 'stakeable',\n",
       " 'underlyingasset',\n",
       " 'dancefloors',\n",
       " 'nbpa',\n",
       " 'basepool',\n",
       " 'rott',\n",
       " 'atcc',\n",
       " 'libconvert',\n",
       " 'dopest',\n",
       " 'techonology',\n",
       " 'bucketmanager',\n",
       " 'generalobligation',\n",
       " 'kazm',\n",
       " 'kyu',\n",
       " 'miva',\n",
       " 'deactive',\n",
       " 'matemticas',\n",
       " 'tbqh',\n",
       " 'fastcompany',\n",
       " 'dvee',\n",
       " 'gridex',\n",
       " 'moonsettlers',\n",
       " 'srinivasans',\n",
       " 'hszpge',\n",
       " 'tagsys',\n",
       " 'nicols',\n",
       " 'methanofullerene',\n",
       " 'rgpg',\n",
       " 'valerie',\n",
       " 'proft',\n",
       " 'berea',\n",
       " 'getnext',\n",
       " 'revolutonise',\n",
       " 'maintnance',\n",
       " 'hermez',\n",
       " 'gowth',\n",
       " 'momtazi',\n",
       " 'patel',\n",
       " 'roachkilla',\n",
       " 'stkcvxfrxeth',\n",
       " 'infoshare',\n",
       " 'comissioned',\n",
       " 'optimizies',\n",
       " 'principlesabstract',\n",
       " 'memish',\n",
       " 'methodoligies',\n",
       " 'euroliga',\n",
       " 'dubble',\n",
       " 'koppany',\n",
       " 'infinitum',\n",
       " 'photopea',\n",
       " 'cagr',\n",
       " 'eqfees',\n",
       " 'tatrabanka',\n",
       " 'lpseven',\n",
       " 'angzaaroutpost',\n",
       " 'optimalutilization',\n",
       " 'cygni',\n",
       " 'oneil',\n",
       " 'fabrick',\n",
       " 'daotoken',\n",
       " 'openscience',\n",
       " 'desaturated',\n",
       " 'postgame',\n",
       " 'akuizad',\n",
       " 'mrnerdhair',\n",
       " 'eoling',\n",
       " 'rager',\n",
       " 'intentar',\n",
       " 'eulerlinearpoolfactory',\n",
       " 'theodor',\n",
       " 'ffeeplease',\n",
       " 'manupilated',\n",
       " 'tking',\n",
       " 'bednar',\n",
       " 'alextnetto',\n",
       " 'ome',\n",
       " 'sendtoken',\n",
       " 'minichef',\n",
       " 'michaelf',\n",
       " 'truflation',\n",
       " 'vaste',\n",
       " 'webgnar',\n",
       " 'fragances',\n",
       " 'tsingtech',\n",
       " 'discordwebsocket',\n",
       " 'dunequery',\n",
       " 'dudas',\n",
       " 'foxducks',\n",
       " 'juld',\n",
       " 'cryptofairy',\n",
       " 'jarmbkeh',\n",
       " 'ninguno',\n",
       " 'ipzwsak',\n",
       " 'arbonesetatlasminbasefeeaction',\n",
       " 'thanawut',\n",
       " 'avatarshape',\n",
       " 'differnce',\n",
       " 'tganits',\n",
       " 'dgneth',\n",
       " 'scrine',\n",
       " 'azerty',\n",
       " 'ethbogat',\n",
       " 'relocks',\n",
       " 'talkin',\n",
       " 'trustlines',\n",
       " 'flt',\n",
       " 'elton',\n",
       " 'entrnace',\n",
       " 'evidince',\n",
       " 'setsubnodeowner',\n",
       " 'timrpeterson',\n",
       " 'comienzan',\n",
       " 'everlywell',\n",
       " 'cryptotoadz',\n",
       " 'xbnta',\n",
       " 'internalcomms',\n",
       " 'myne',\n",
       " 'manifestar',\n",
       " 'glicpixxxver',\n",
       " 'eols',\n",
       " 'petpark',\n",
       " 'rlbtfly',\n",
       " 'necesariamente',\n",
       " 'aregoing',\n",
       " 'qmesnev',\n",
       " 'encuesta',\n",
       " 'poolrecovery',\n",
       " 'istagram',\n",
       " 'milkou',\n",
       " 'optimismrootgauge',\n",
       " 'godzilla',\n",
       " 'beansperfertilizer',\n",
       " 'unallocating',\n",
       " 'megacap',\n",
       " 'jimpsons',\n",
       " 'nextdao',\n",
       " 'mthood',\n",
       " 'cach',\n",
       " 'smp',\n",
       " 'phx',\n",
       " 'leanly',\n",
       " 'misallocated',\n",
       " 'sassoon',\n",
       " 'briguit',\n",
       " 'smartltv',\n",
       " 'suprise',\n",
       " 'jheeart',\n",
       " 'panke',\n",
       " 'whd',\n",
       " 'consideredetc',\n",
       " 'npucudp',\n",
       " 'chaherli',\n",
       " 'czrx',\n",
       " 'boohoo',\n",
       " 'isfertilizing',\n",
       " 'ishares',\n",
       " 'goddessdao',\n",
       " 'branda',\n",
       " 'intital',\n",
       " 'tictok',\n",
       " 'bidimensionnal',\n",
       " 'sphingolipid',\n",
       " 'npaw',\n",
       " 'konduru',\n",
       " 'tokonomics',\n",
       " 'domas',\n",
       " 'nunca',\n",
       " 'grotesk',\n",
       " 'kwon',\n",
       " 'mesmo',\n",
       " 'scheilling',\n",
       " 'cryptorewards',\n",
       " 'veboostdelegation',\n",
       " 'makeanft',\n",
       " 'balancertokenadmin',\n",
       " 'apolwmatic',\n",
       " 'gfc',\n",
       " 'araw',\n",
       " 'minigaames',\n",
       " 'attendence',\n",
       " 'hellooo',\n",
       " 'proyector',\n",
       " 'apyspread',\n",
       " 'accessibly',\n",
       " 'hartnell',\n",
       " 'relastic',\n",
       " 'deplyoment',\n",
       " 'ecosystemwith',\n",
       " 'thrashy',\n",
       " 'bousfield',\n",
       " 'ori',\n",
       " 'optimiums',\n",
       " 'floorsweeper',\n",
       " 'mortage',\n",
       " 'catu',\n",
       " 'modelize',\n",
       " 'macbook',\n",
       " 'obront',\n",
       " 'prismarisk',\n",
       " 'xiaohongshu',\n",
       " 'odx',\n",
       " 'retirable',\n",
       " 'organicborrowapy',\n",
       " 'donatiom',\n",
       " 'ttulo',\n",
       " 'bidirectionally',\n",
       " 'illuvitar',\n",
       " 'multsigs',\n",
       " 'hacxyk',\n",
       " 'timeouts',\n",
       " 'estmarks',\n",
       " 'progess',\n",
       " 'metricsgarden',\n",
       " 'djtrax',\n",
       " 'cybergalz',\n",
       " 'autcompounding',\n",
       " 'andtech',\n",
       " 'retrun',\n",
       " 'zawiasa',\n",
       " 'clockify',\n",
       " 'hirad',\n",
       " 'apeworx',\n",
       " 'suckaburger',\n",
       " 'overpeg',\n",
       " 'thedapplist',\n",
       " 'nansenarkham',\n",
       " 'everyoneauditors',\n",
       " 'hanson',\n",
       " 'modularly',\n",
       " 'protocollinearpoolfactory',\n",
       " 'nonfungibility',\n",
       " 'canil',\n",
       " 'openseaonly',\n",
       " 'communityin',\n",
       " 'mercle',\n",
       " 'masterminter',\n",
       " 'furather',\n",
       " 'lushnikov',\n",
       " 'wt',\n",
       " 'nametags',\n",
       " 'viceversa',\n",
       " 'cryptoblivious',\n",
       " 'recolors',\n",
       " 'kreischer',\n",
       " 'fastmpc',\n",
       " 'strykes',\n",
       " 'subcomponent',\n",
       " 'proposa',\n",
       " 'rngenerator',\n",
       " 'roofstock',\n",
       " 'whisher',\n",
       " 'bitspossessed',\n",
       " 'aavedoes',\n",
       " 'gorey',\n",
       " 'headge',\n",
       " 'waifuwonderland',\n",
       " 'remainingfunding',\n",
       " 'ethresear',\n",
       " 'parbb',\n",
       " 'jord',\n",
       " 'wlds',\n",
       " 'shelb',\n",
       " 'decentralizacion',\n",
       " 'guate',\n",
       " 'playcanvas',\n",
       " 'subdiv',\n",
       " 'momentpowered',\n",
       " 'hypophosphatemic',\n",
       " 'daon',\n",
       " 'bonventre',\n",
       " 'opcin',\n",
       " 'coore',\n",
       " 'cuestin',\n",
       " 'designees',\n",
       " 'bizzo',\n",
       " 'lavanet',\n",
       " 'increae',\n",
       " 'loackme',\n",
       " 'dopewar',\n",
       " 'krtwrsrnrkukwdekot',\n",
       " 'galssmarkets',\n",
       " 'blockslplit',\n",
       " 'vero',\n",
       " 'kee',\n",
       " 'oppening',\n",
       " 'mandato',\n",
       " 'andvoila',\n",
       " 'icecast',\n",
       " 'ownsers',\n",
       " 'inft',\n",
       " 'cctv',\n",
       " 'workoutme',\n",
       " 'xemm',\n",
       " 'kdxvbafgd',\n",
       " 'drmsxmchns',\n",
       " 'sucedan',\n",
       " 'tipjar',\n",
       " 'alamada',\n",
       " 'otterclam',\n",
       " 'themoma',\n",
       " 'jaylegacy',\n",
       " 'sustainalibity',\n",
       " 'wxbtrfly',\n",
       " 'pygame',\n",
       " 'jasperthefriendlyghost',\n",
       " 'deflationly',\n",
       " 'verasity',\n",
       " 'dogstoevskys',\n",
       " 'guni',\n",
       " 'xva',\n",
       " 'kiriyha',\n",
       " 'postarchitekt',\n",
       " 'tinshui',\n",
       " 'getwhitelistedoperators',\n",
       " 'hagen',\n",
       " 'bpttodivest',\n",
       " 'zrich',\n",
       " 'resilence',\n",
       " 'samantha',\n",
       " 'eastmont',\n",
       " 'lmk',\n",
       " 'professonal',\n",
       " 'implemention',\n",
       " 'gotham',\n",
       " 'cryptoguard',\n",
       " 'ntzns',\n",
       " 'piester',\n",
       " 'formatis',\n",
       " 'prmtrl',\n",
       " 'taclx',\n",
       " 'romanowski',\n",
       " 'glamguerilla',\n",
       " 'mltiple',\n",
       " 'angeldao',\n",
       " 'hydroxamate',\n",
       " 'intp',\n",
       " 'autobidders',\n",
       " 'easyfi',\n",
       " 'ethdrive',\n",
       " 'paragondcl',\n",
       " 'nicolau',\n",
       " 'davinoyesigye',\n",
       " 'weah',\n",
       " 'redocumenting',\n",
       " 'spycebringer',\n",
       " 'multip',\n",
       " 'favortoken',\n",
       " 'advancedpipecall',\n",
       " 'jissle',\n",
       " 'sva',\n",
       " 'kazenokai',\n",
       " 'anjos',\n",
       " 'domenic',\n",
       " 'delelgate',\n",
       " 'czekay',\n",
       " 'hdk',\n",
       " 'barra',\n",
       " 'initbipsunriseimprovements',\n",
       " 'kristi',\n",
       " 'deltaneutral',\n",
       " 'erooms',\n",
       " 'getcurrenthumidity',\n",
       " 'woorton',\n",
       " 'eabd',\n",
       " 'wakeboarder',\n",
       " 'activty',\n",
       " 'experiencein',\n",
       " 'synergynodes',\n",
       " 'cahuenga',\n",
       " 'alreadyinflated',\n",
       " 'easly',\n",
       " 'signataidentity',\n",
       " 'dappand',\n",
       " 'upregulate',\n",
       " 'numer',\n",
       " 'bcbb',\n",
       " 'isps',\n",
       " 'caregiving',\n",
       " 'holysmokes',\n",
       " 'tempel',\n",
       " 'desagree',\n",
       " 'revocados',\n",
       " 'hpxl',\n",
       " 'ictx',\n",
       " 'pshe',\n",
       " 'pinetools',\n",
       " 'lockedcant',\n",
       " 'stallone',\n",
       " 'mcgurk',\n",
       " 'xinch',\n",
       " 'fiatcrypto',\n",
       " 'routable',\n",
       " 'vitalians',\n",
       " 'ereals',\n",
       " 'bina',\n",
       " 'communidad',\n",
       " 'dthe',\n",
       " 'disablebridgeadapters',\n",
       " 'strongholdsec',\n",
       " 'prevening',\n",
       " 'protocolids',\n",
       " 'osman',\n",
       " 'goong',\n",
       " 'autocompounder',\n",
       " 'shellscripts',\n",
       " 'probablly',\n",
       " 'dugans',\n",
       " 'consideation',\n",
       " 'mpbrhszhzjpx',\n",
       " 'bpro',\n",
       " 'protype',\n",
       " 'balbattles',\n",
       " 'roleplace',\n",
       " 'rttm',\n",
       " 'fleekhq',\n",
       " 'snes',\n",
       " 'singlefinance',\n",
       " 'cvis',\n",
       " 'lennykravitz',\n",
       " 'susik',\n",
       " 'tdy',\n",
       " 'creatie',\n",
       " 'xmare',\n",
       " 'hoa',\n",
       " 'newsilver',\n",
       " 'tricryptofactory',\n",
       " 'camerota',\n",
       " 'diffcult',\n",
       " 'compleated',\n",
       " 'moonbase',\n",
       " 'dothedamndishes',\n",
       " 'thermo',\n",
       " 'frogmonkees',\n",
       " 'kapatkeydao',\n",
       " 'cakezksync',\n",
       " 'topgrading',\n",
       " 'tenz',\n",
       " 'priorization',\n",
       " 'typefully',\n",
       " 'descisions',\n",
       " 'paramenters',\n",
       " 'szns',\n",
       " 'dondochaka',\n",
       " 'interopability',\n",
       " 'polkabee',\n",
       " 'gigabrain',\n",
       " 'debtohm',\n",
       " 'idealpathwaybalance',\n",
       " 'dfea',\n",
       " 'coinbaseventures',\n",
       " 'airburshed',\n",
       " 'eknobl',\n",
       " 'yemels',\n",
       " 'cliffside',\n",
       " 'bitpanda',\n",
       " ...}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "documents = (\n",
    "    item \n",
    "    for sub in (\n",
    "        str(x).split() for x in df_[\"body_filtered\"]\n",
    "    ) \n",
    "    for item in sub\n",
    ")\n",
    "\n",
    "word_counts = Counter(documents)\n",
    "print(len(word_counts))\n",
    "single = set([\n",
    "    word \n",
    "    for word, count in word_counts.items() \n",
    "    if count <= 1 and not is_word_in_dictionary(word)\n",
    "])\n",
    "print(len(single))\n",
    "single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda x: ' '.join(\n",
    "        xx for xx in x.split() if xx not in single\n",
    "    ).strip()\n",
    "func = np.vectorize(func)\n",
    "df_[\"body_filtered\"] = func(df_[\"body_filtered\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Categorized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((264, 41), (20188, 41))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_cols = [\"Class A\", \"Class B\", \"Class C\"]\n",
    "\n",
    "df_class = df_[df_[class_cols].notnull().any(axis=1)].sort_values(by=['body_filtered'])\n",
    "df_not = df_[df_[class_cols].isnull().all(axis=1)].sort_values(by=['body_filtered'])\n",
    "df_body = pd.concat([df_class[\"body_filtered\"], df_not[\"body_filtered\"]])\n",
    "df_class.shape, df_not.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 20188)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(df_body)\n",
    "df_class_body = X[:df_class.shape[0]]\n",
    "df_not_body = X[df_class.shape[0]:]\n",
    "\n",
    "cos_mat = cosine_similarity(df_class_body, df_not_body)\n",
    "print(cos_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"similarity\", \"id_c\", \"space_id_c\", \"title_c\", \"body_c\", \"link_c\", \"id_n\", \"space_id_n\", \"title_n\", \"body_n\", \"link_n\"]\n",
    "df_columns = [\"id\", \"space_id\", \"title\", \"body\", \"link\"]\n",
    "\n",
    "def print_line(data):\n",
    "    print(\"[ID]:\", data[\"id\"])\n",
    "    print(\"[Space ID]:\", data[\"space_id\"])\n",
    "    print(\"[Title]:\", data[\"title\"])\n",
    "    print(data[\"body\"])\n",
    "\n",
    "def find_similar(threshold: int, threshold_upper: int=2, doPrint: bool = False):\n",
    "    global cos_mat, df_class, df_not, columns, class_cols, df_columns\n",
    "\n",
    "    temp = {k: None for k in columns + class_cols}\n",
    "    result = []\n",
    "    over = (cos_mat >= threshold) & (threshold_upper > cos_mat)\n",
    "\n",
    "    for i in (i for i, v in enumerate(over.sum(axis=1)) if v > 0):\n",
    "        y = df_class.iloc[i]\n",
    "        if doPrint:\n",
    "            print(\"-------------------------------------\")\n",
    "            print(\"-------------------------------------\")\n",
    "            print(\"[Category]:\", y[\"Class A\"], y[\"Class B\"], y[\"Class C\"], sep=\"\\t\")\n",
    "            print_line(y)\n",
    "            print(\"-------------------------------------\")\n",
    "        for v in df_columns:\n",
    "            temp[v+\"_c\"] = y[v]\n",
    "        for v in class_cols:\n",
    "            temp[v] = y[v]\n",
    "\n",
    "        \n",
    "        for j in (idx for idx, v in enumerate(over[i]) if v): \n",
    "            x = df_not.iloc[j]\n",
    "            if doPrint:\n",
    "                print(f\"{cos_mat[i, j]}\")\n",
    "                print_line(x)\n",
    "                print(\"======================\\n\\n\")\n",
    "            temp[\"similarity\"] = cos_mat[i, j]\n",
    "            for v in df_columns:\n",
    "                temp[v+\"_n\"] = x[v]\n",
    "            result.append(temp.copy())\n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 14)\n",
      "(61, 14)\n",
      "(93, 14)\n",
      "(58, 14)\n",
      "(82, 14)\n"
     ]
    }
   ],
   "source": [
    "panel = [2, 1, 0.9, 0.8, 0.7, 0.6] # 0.6은 별로\n",
    "df_panel = {}\n",
    "for i in range(len(panel)-1):\n",
    "    result = find_similar(threshold=panel[i+1], threshold_upper=panel[i])\n",
    "    df_panel[f\"over{panel[i+1]}\"] = result\n",
    "    print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before removing proper nouns\n",
    "# (50, 14)\n",
    "# (58, 14)\n",
    "# (76, 14)\n",
    "# (66, 14)\n",
    "# (60, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'similar_categorized_filtered.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "    for k in df_panel.keys():\n",
    "        df_panel[k].to_excel(writer, sheet_name=k, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Categorized Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not = df_not[~df_not[\"id\"].isin(df_panel[\"over1\"][\"id_n\"])]\n",
    "df_not = df_not[~df_not[\"id\"].isin(df_panel[\"over0.9\"][\"id_n\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20121, 20121)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df_not[\"body_filtered\"])\n",
    "cos_mat = cosine_similarity(X, X)\n",
    "cos_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def find_similar_cluster(threshold: int, threshold_upper:int=2):\n",
    "    G = nx.Graph()\n",
    "    for idx in range(len(df_not)):\n",
    "        G.add_node(df_not.iloc[idx][\"id\"])\n",
    "\n",
    "    over = (cos_mat >= threshold) & (threshold_upper > cos_mat) \n",
    "    for i in range(len(df_not)):\n",
    "        for j in range(i + 1, len(df_not)):\n",
    "            if over[i, j]:\n",
    "                G.add_edge(df_not.iloc[i][\"id\"], df_not.iloc[j][\"id\"], weight=cos_mat[i, j])\n",
    "\n",
    "    filtered_components = [\n",
    "        df_not[df_not[\"id\"].isin(list(c))][[\"id\", \"space_id\", \"title\", \"body\", \"link\", \"Class A\", \"Class B\", \"Class C\"]]\n",
    "        for c in list(nx.connected_components(G)) \n",
    "        if len(c) >= 2\n",
    "    ]\n",
    "    filtered_components = sorted(filtered_components, key=lambda x: len(x), reverse=True)\n",
    "\n",
    "    rows = 0\n",
    "    output_file = f'df_not_{threshold}_filtered.xlsx'\n",
    "    with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "        for i, component in enumerate(filtered_components):\n",
    "            component.to_excel(writer, sheet_name=str(i), index=False)\n",
    "            rows += component.shape[0]\n",
    "    print(f\"Number of rows with threshold {threshold}: {rows}\")\n",
    "    return filtered_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with threshold 1: 1545\n",
      "1 471\n",
      "Number of rows with threshold 0.9: 3406\n",
      "0.9 1061\n",
      "Number of rows with threshold 0.8: 2733\n",
      "0.8 613\n",
      "Number of rows with threshold 0.7: 3708\n",
      "0.7 778\n",
      "Number of rows with threshold 0.6: 5130\n",
      "0.6 931\n"
     ]
    }
   ],
   "source": [
    "panel = [2, 1, 0.9, 0.8, 0.7, 0.6]\n",
    "for i in range(len(panel)-1):\n",
    "    filtered_components = find_similar_cluster(threshold=panel[i+1], threshold_upper=panel[i])\n",
    "    print(panel[i+1], len(filtered_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
